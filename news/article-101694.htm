<!doctype html>
<html lang="en">

<head>
        <link rel="canonical" href="https://windowsclashnode.github.io/news/article-101694.htm" />
    <!-- Required Meta Tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Document Title, Description, and Author -->
    <title>PyTorch的自动求导机制详细解析，PyTorch的核心魔法</title>
        <meta name="description" content="点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”   作者：Vaibhav Kumar 编译：ronghuaiyang   导读 这篇文章详细解析了PyTorch的自动求导机制，让你了解Py" />
        <link rel="icon" href="/assets/website/img/windowsclashnode/favicon.ico" type="image/x-icon"/>

    <meta name="author" content="WindowsClashNode节点订阅站">
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://windowsclashnode.github.io/news/article-101694.htm" />
    <meta property="og:site_name" content="WindowsClashNode节点订阅站" />
    <meta property="og:title" content="PyTorch的自动求导机制详细解析，PyTorch的核心魔法" />
    <meta property="og:image" content="https://windowsclashnode.github.io/uploads/20240618/b1fbba63249f346b6dc3986d543a2fcf.webp" />
        <meta property="og:release_date" content="2025-04-22T08:25:25" />
    <meta property="og:updated_time" content="2025-04-22T08:25:25" />
        <meta property="og:description" content="点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”   作者：Vaibhav Kumar 编译：ronghuaiyang   导读 这篇文章详细解析了PyTorch的自动求导机制，让你了解Py" />
        
    <meta name="applicable-device" content="pc,mobile" />
    <meta name="renderer" content="webkit" />
    <meta name="force-rendering" content="webkit" />
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta name="robots" content="max-image-preview:large" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="PyTorch的自动求导机制详细解析，PyTorch的核心魔法">
    <meta name="format-detection" content="telephone=no">

    <link rel="dns-prefetch" href="https:/www.googletagmanager.com">
    <link rel="dns-prefetch" href="https://www.googleadservices.com">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link rel="dns-prefetch" href="https://pagead2.googlesyndication.com">
    <link rel="dns-prefetch" href="https://cm.g.doubleclick.net">
    
    <!-- Google Fonts Files -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,500;0,600;0,700;0,800;0,900;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Condensed:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap" rel="stylesheet">
    <!-- CSS Files -->
    <link rel="stylesheet" href="/assets/website/css/windowsclashnode/hello-bsb.css">
    <link rel="stylesheet" href="/assets/website/css/G.css" />
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FQY7STE0Q8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FQY7STE0Q8');
</script>    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body data-bs-spy="scroll" data-bs-target="#bsb-tpl-navbar" data-bs-smooth-scroll="true" tabindex="0" data-page="detail">
        <!-- Header -->
    <header id="header" class="sticky-top bsb-tpl-header-sticky bsb-tpl-header-sticky-animationX">
        <!-- Navbar 1 - Bootstrap Brain Component -->
        <nav id="scrollspyNav" class="navbar navbar-expand-lg bsb-tpl-bg-alabaster bsb-navbar bsb-navbar-hover bsb-navbar-caret bsb-tpl-navbar-sticky" data-bsb-sticky-target="#header">
            <div class="container">
                <a class="navbar-brand" href="/">
                                <span>Windows ClashNode</span>
                                </a>
                <button class="navbar-toggler border-0" type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvasNavbar" aria-controls="offcanvasNavbar">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="bi bi-list" viewBox="0 0 16 16">
                        <path fill-rule="evenodd" d="M2.5 12a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5zm0-4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 0 1H3a.5.5 0 0 1-.5-.5z" />
                    </svg>
                </button>
                <div class="offcanvas offcanvas-end" tabindex="-1" id="offcanvasNavbar" aria-labelledby="offcanvasNavbarLabel">
                    <div class="offcanvas-header">
                        <h5 class="offcanvas-title" id="offcanvasNavbarLabel">Menu</h5>
                        <button type="button" class="btn-close" data-bs-dismiss="offcanvas" aria-label="Close"></button>
                    </div>
                    <div class="offcanvas-body">
                        <ul id="bsb-tpl-navbar" class="navbar-nav justify-content-end flex-grow-1">
                                                        <li class="nav-item">
                                <a class="nav-link" href="/">首页</a>
                            </li>
                                                        <li class="nav-item">
                                <a class="nav-link" href="/free-nodes/">免费节点</a>
                            </li>
                                                        <li class="nav-item">
                                <a class="nav-link" href="/paid-subscribe/">推荐机场</a>
                            </li>
                                                        <li class="nav-item">
                                <a class="nav-link" href="/client.htm">客户端</a>
                            </li>
                                                        <li class="nav-item">
                                <a class="nav-link" href="/news/">新闻资讯</a>
                            </li>
                                                    </ul>
                    </div>
                </div>
            </div>
        </nav>
    </header>
    <!-- Hero 3 - Bootstrap Brain Component -->
    <section id="scrollspyHero" class="bsb-tpl-bg-alabaster pt-3 pt-xl-2 list">
        <div class="container overflow-hidden">
            <div class="row gy-5 gy-lg-0">
                <div class="col-12 col-lg-6 slogan">
                    <h1 class="display-3 fw-bold mb-3">PyTorch的自动求导机制详细解析，PyTorch的核心魔法 </h1>
                    <p class="fs-4 mb-5">
                        <a href="/">首页</a> / <a href="/news/">新闻资讯</a> / <span>正文</span>
                    </p>
                </div>
                <div class="col-12 col-lg-5 text-center">
                    <div class="position-relative">
                        <div class="bsb-circle border border-4 border-accent position-absolute top-50 start-10 translate-middle z-1"></div>
                        <div class="bsb-circle bg-primary position-absolute top-50 start-50 translate-middle" style="--bsb-cs: 460px;"></div>
                        <div class="bsb-circle border border-4 border-accent position-absolute top-10 end-0 z-1" style="--bsb-cs: 100px;"></div>
                        <img class="img-fluid position-relative z-2" loading="lazy" href="/assets/website/img/windowsclashnode/hero/hero-img-1.webp" alt="">
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- Main -->
    <main id="main">
        <!-- Process 1 - Bootstrap Brain Component -->
        <section id="scrollspyAbout" class="py-5 py-xl-8 py-xxl-16">
            <div class="container">
                <div class="row">
                    <div class="col-md-9">
                                        <input type="hidden" id="share-website-info" data-name="" data-url="">
                <div class="xcblog-blog-detail">
                      				  				  				<div id="content_views" class="htmledit_views"> <div class="rich_media_content" id="js_content"> <p style="color:inherit;font-size:inherit;min-height:1em;letter-spacing:.544px;font-family:'微软雅黑';line-height:inherit;text-align:center;"><span style="font-size:14px;">点击上方“AI公园”，关注公众号，选择加“星标“或“置顶”</span></p> <hr style="color:inherit;font-size:inherit;letter-spacing:.544px;font-family:'微软雅黑';line-height:inherit;border-right:none;border-bottom:none;border-left:none;border-top-style:dashed;border-top-color:rgb(165,165,165);"/> <blockquote style="letter-spacing:.544px;"> <p style="min-height:1em;letter-spacing:.544px;font-family:'微软雅黑';font-size:16px;"><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">作</span><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">者：</span><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">Vaibhav Kumar</span></p> <p style="min-height:1em;letter-spacing:.544px;text-indent:0em;font-family:'微软雅黑';font-size:16px;color:rgb(62,62,62);"><span style="font-family:Calibri;color:rgb(0,0,0);font-size:14px;">编译：ronghuaiyang</span></p> </blockquote> <p> <span style="color:inherit;font-size:14px;"><strong style="color:rgb(102,102,102);"><span style="border-color:rgb(252,180,43);color:rgb(255,255,255);text-align:center;letter-spacing:2px;line-height:1.75em;">导读</span></strong></span></p> <p style="min-height:1em;color:inherit;letter-spacing:1.5px;line-height:1.75em;text-indent:0em;">这篇文章详细解析了PyTorch的自动求导机制，让你了解PyTorch的核心魔法。</p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/74b184c9f16e43d1c194885948f2eaf6.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p><span style="font-size:14px;"></span></p> <p> <center></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/0d23465615adfed4405b360b7e0ce2f2.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p>  <span style="font-size:14px;"></span><br />  </center><br />  <center><br />   <span style="font-size:14px;">在这个过程中，它从不显式地构造整个雅可比矩阵。</span><br />   <span style="font-size:14px;">直接计算JVP通常更简单、更有效。</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">我们都同意，当涉及到大型神经网络时，我们都不擅长微积分。通过显式求解数学方程来计算这样大的复合函数的梯度是不现实的，特别是这些曲线存在于大量的维数中，是无法理解的。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">要处理14维空间中的超平面，想象一个三维空间，大声地对自己说“14”。每个人都这么做——Geoffrey Hinton</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这就是PyTorch的autograd发挥作用的地方。它抽象了复杂的数学，帮助我们“神奇地”计算高维曲线的梯度，只需要几行代码。这篇文章试图描述autograd的魔力。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">PyTorch基础</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在进一步讨论之前，我们需要了解一些基本的PyTorch概念。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">张量：简单地说，它只是PyTorch中的一个n维数组。张量支持一些额外的增强，这使它们独一无二：除了CPU，它们可以加载或GPU更快的计算。在设置<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.requires_grad = True</code>的时候，他们开始形成一个反向图，跟踪应用于他们的每个操作，使用所谓的动态计算图(DCG)计算梯度(后面会进一步解释)。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在早期版本的PyTorch中，使用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.autograd.Variable</code>类用于创建支持梯度计算和操作跟踪的张量，但截至PyTorch v0.4.0，Variable类已被禁用。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.Tensor</code>和<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.autograd.Variable</code>现在是同一个类。更准确地说， <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.Tensor</code>能够跟踪历史并表现得像旧的<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Variable</code>。</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">torch</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">numpy</span> <span class="cm-keyword" style="font-size:14px;">as</span> <span class="cm-variable" style="font-size:14px;">np</span></span></span><br/><span style="font-size:14px;">&nbsp;</span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">randn</span>(<span class="cm-number" style="font-size:14px;">2</span>, <span class="cm-number" style="font-size:14px;">2</span>, <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;</span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># From numpy</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">np</span>.<span class="cm-property" style="font-size:14px;">array</span>([<span class="cm-number" style="font-size:14px;">1.</span>, <span class="cm-number" style="font-size:14px;">2.</span>, <span class="cm-number" style="font-size:14px;">3.</span>]) <span class="cm-comment" style="font-size:14px;">#Only Tensors of floating point dtype can require gradients</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">from_numpy</span>(<span class="cm-variable" style="font-size:14px;">x</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># Now enable gradient</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span>.<span class="cm-property" style="font-size:14px;">requires_grad_</span>(<span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># _ above makes the change in-place (its a common pytorch thing)</span></span></pre> <p><span style="font-size:14px;"></span></p> <p> <center><br />   <span style="font-size:14px;">创建启用梯度的张量的各种方法的代码</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><strong>注意</strong>：根据PyTorch的设计，梯度只能计算浮点张量，这就是为什么我创建了一个浮点类型的numpy数组，然后将它设置为启用梯度的PyTorch张量。</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Autograd：</strong><strong></strong>这个类是一个计算导数的引擎(更精确地说是雅克比向量积)。它记录了梯度张量上所有操作的一个图，并创建了一个称为动态计算图的非循环图。这个图的叶节点是输入张量，根节点是输出张量。梯度是通过跟踪从根到叶的图形，并使用链式法则将每个梯度相乘来计算的。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">神经网络和反向传播</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">神经网络只不过是经过精心调整(训练)以输出所需结果的复合数学函数。调整或训练是通过一种称为反向传播的出色算法完成的。反向传播用来计算相对于输入权值的损失梯度，以便以后更新权值，最终减少损失。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">在某种程度上，反向传播只是链式法则的一个花哨的名字—— Jeremy Howard</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">创建和训练神经网络包括以下基本步骤：</span></p> <ol class="ol-list list-paddingleft-2"> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">定义体系结构</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">使用输入数据在体系结构上向前传播</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">计算损失</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><strong>反向传播，计算每个权重的梯度</strong><strong></strong></span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">使用学习率更新权重</span></p> </li> </ol> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">损失变化引起的输入权值的微小变化称为该权值的梯度，并使用反向传播计算。然后使用梯度来更新权值，使用学习率来整体减少损失并训练神经网络。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这是以迭代的方式完成的。对于每个迭代，都要计算几个梯度，并为存储这些梯度函数构建一个称为计算图的东西。PyTorch通过构建一个动态计算图(DCG)来实现这一点。此图在每次迭代中从头构建，为梯度计算提供了最大的灵活性。例如，对于前向操作(函数)<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Mul</code></span><span style="font-size:14px;"> ，向后操作函数<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">MulBackward</code>被动态集成到后向图中以计算梯度。</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">动态计算图</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">支持梯度的张量(变量)和函数(操作)结合起来创建动态计算图。数据流和应用于数据的操作在运行时定义，从而动态地构造计算图。这个图是由底层的autograd类动态生成的。你不必在启动训练之前对所有可能的路径进行编码——你运行的是你所区分的。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">一个简单的DCG用于两个张量的乘法会是这样的：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/45e34b846476039c94016f89f14506a6.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">带有requires_grad = False的DCG</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">图中的每个点轮廓框是一个变量，紫色矩形框是一个操作。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">每个变量对象都有几个成员，其中一些成员是：</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Data</strong>：它是一个变量持有的数据。<strong>x</strong>持有一个1x1张量，其值等于1.0，而<strong>y</strong>持有2.0。<strong>z</strong>持有两个的乘积，即2.0。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>requires_grad</strong>：这个成员(如果为true)开始跟踪所有的操作历史，并形成一个用于梯度计算的向后图。对于任意张量<strong>a</strong>，可以按如下方式对其进行原地处理：<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">a.requires_grad_(True)</code>。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>grad:</strong> grad保存梯度值。如果<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code> 为False，它将持有一个None值。即使<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code> 为真，它也将持有一个None值，除非从其他节点调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.backward()</code>函数。例如，如果你对<strong>out</strong>关于<strong>x</strong>计算梯度，调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">out.backward()</code>，则<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x.grad</code>的值为<strong>∂out/∂x</strong>。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>grad_fn</strong>：这是用来计算梯度的向后函数。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>is_leaf</strong>：如果：</span></p> <ol class="ol-list list-paddingleft-2"> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它被一些函数显式地初始化，比如<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x = torch.tensor(1.0)</code>或<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x = torch.randn(1, 1)</code>(基本上是本文开头讨论的所有张量初始化方法)。</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它是在张量的操作之后创建的，所有张量都有<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad = False</code>。</span></p> </li> <li> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">它是通过对某个张量调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.detach()</code>方法创建的。</span></p> </li> </ol> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward()</code>时，只计算<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad</code>和<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">is_leaf</code>同时为真的节点的梯度。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">当打开 <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">requires_grad = True</code>时，PyTorch将开始跟踪操作，并在每个步骤中存储梯度函数，如下所示：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/5d458ba5bc4aa41de544540a487b5e44.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">requires_grad = True的DCG</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">在PyTorch下生成上图的代码是：</span></p> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">Backward()函数</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">Backward函数实际上是通过传递参数(默认情况下是1x1单位张量)来计算梯度的，它通过Backward图一直到每个叶节点，每个叶节点都可以从调用的根张量追溯到叶节点。然后将计算出的梯度存储在每个叶节点的<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.grad</code>中。<em>请记住，在正向传递过程中已经动态生成了后向图。</em><em>backward函数仅使用已生成的图形计算梯度，并将其存储在叶节点中。</em></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">让我们分析以下代码：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-keyword" style="font-size:14px;">import</span> <span class="cm-variable" style="font-size:14px;">torch</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"># Creating the graph</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>(<span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span> = <span class="cm-variable" style="font-size:14px;">x</span> <span class="cm-operator" style="font-size:14px;">**</span> <span class="cm-number" style="font-size:14px;">3</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span>.<span class="cm-property" style="font-size:14px;">backward</span>() <span class="cm-comment" style="font-size:14px;">#Computes the gradient</span></span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-builtin" style="font-size:14px;">print</span>(<span class="cm-variable" style="font-size:14px;">x</span>.<span class="cm-property" style="font-size:14px;">grad</span>.<span class="cm-property" style="font-size:14px;">data</span>) <span class="cm-comment" style="font-size:14px;">#Prints '3' which is dz/dx</span></span></span></pre> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">需要注意的一件重要事情是，当调用<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code>时，一个张量会自动传递为<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward(torch.tensor(1.0))</code>。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">torch.tensor(1.0)</code>是用来终止链式法则梯度乘法的外部梯度。这个外部梯度作为输入传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">MulBackward</code>函数，以进一步计算<strong>x</strong>的梯度。传递到<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">.backward()</code>中的张量的维数必须与正在计算梯度的张量的维数相同。例如，如果梯度支持张量x和y如下：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">x</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>([<span class="cm-number" style="font-size:14px;">0.0</span>, <span class="cm-number" style="font-size:14px;">2.0</span>, <span class="cm-number" style="font-size:14px;">8.0</span>], <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">y</span> = <span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">tensor</span>([<span class="cm-number" style="font-size:14px;">5.0</span> , <span class="cm-number" style="font-size:14px;">1.0</span> , <span class="cm-number" style="font-size:14px;">7.0</span>], <span class="cm-variable" style="font-size:14px;">requires_grad</span> = <span class="cm-keyword" style="font-size:14px;">True</span>)</span></span><br/><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span> = <span class="cm-variable" style="font-size:14px;">x</span> <span class="cm-operator" style="font-size:14px;">*</span> <span class="cm-variable" style="font-size:14px;">y</span></span></span></pre> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">然后，要计算<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z</code>关于<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">x</code>或者<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">y</code>的梯度，需要将一个外部梯度传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code>函数，如下所示：</span></p> <pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" style="font-size:.9em;text-align:left;background-image:inherit;background-position:inherit;background-repeat:inherit;background-attachment:inherit;border-width:1px;border-style:solid;border-color:rgb(231,234,237);width:inherit;"><span style="font-size:14px;">&nbsp;<span style="font-size:14px;"><span class="cm-variable" style="font-size:14px;">z</span>.<span class="cm-property" style="font-size:14px;">backward</span>(<span class="cm-variable" style="font-size:14px;">torch</span>.<span class="cm-property" style="font-size:14px;">FloatTensor</span>([<span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-number" style="font-size:14px;">1.0</span>, <span class="cm-number" style="font-size:14px;">1.0</span>])</span></span></pre> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;"><code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">z.backward()</code></span><span style="font-size:14px;"> 会给出 <em>RuntimeError: grad can be implicitly created only for scalar outputs</em><em></em></span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">反向函数传递的张量就像梯度加权输出的权值。从数学上讲，这是一个向量乘以非标量张量的雅可比矩阵(本文将进一步讨论)，因此它几乎总是一个维度的单位张量，与 <code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward</code>张量相同，除非需要计算加权输出。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">tldr ：向后图是由autograd类在向前传递过程中自动动态创建的。<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">Backward()</code>只是通过将其参数传递给已经生成的反向图来计算梯度。</span></p> </blockquote> <h3 class="md-end-block md-heading" style="font-size:1.5em;font-weight:bold;line-height:1.43;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;"><span style="font-size:17px;">数学—雅克比矩阵和向量</span></h3> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">从数学上讲，autograd类只是一个雅可比向量积计算引擎。雅可比矩阵是一个非常简单的单词，它表示两个向量所有可能的偏导数。它是一个向量相对于另一个向量的梯度。</span></p> <blockquote style="border-left-width:4px;border-left-color:rgb(223,226,229);color:rgb(119,119,119);font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"> <p class="md-end-block md-p" style="line-height:inherit;"><span style="font-size:14px;">注意：在这个过程中，PyTorch从不显式地构造整个雅可比矩阵。直接计算JVP (Jacobian vector product)通常更简单、更有效。</span></p> </blockquote> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">如果一个向量<strong>X = [x1, x2，…xn]</strong>通过<strong>f(X) = [f1, f2，…fn]</strong>来计算其他向量，则雅可比矩阵(<strong>J</strong>)包含以下所有偏导组合：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/91836c1d6fbfe79529bef05b61bf4e0c.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p> <center><br />   <span style="font-size:14px;">雅克比矩阵</span><br />  </center></p> <p><span style="font-size:14px;"></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">上面的矩阵表示<strong>f(X)</strong>相对于<strong>X</strong>的梯度。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">假设一个启用PyTorch梯度的张量<strong>X</strong>：</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>X = [x1,x2,…,xn]</strong>(假设这是某个机器学习模型的权值)</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>X</strong>经过一些运算形成一个向量<strong>Y</strong><strong></strong></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;"><strong>Y = f(X) = [y1, y2，…,ym]</strong><strong></strong></span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">然后使用<strong>Y</strong>计算标量损失<strong>l</strong>。假设向量<strong>v</strong>恰好是标量损失<strong>l</strong>关于向量<strong>Y</strong>的梯度，如下：</span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" style="width:258px;" src="http://img.555519.xyz/uploads/20230108/bbaa29ffeba3fecebb34db31d8610d0e.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">向量v称为<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">grad_tensor</code>，并作为参数传递给<code style="border-width:1px;border-style:solid;border-color:rgb(231,234,237);font-size:.9em;">backward()</code> 函数。</span></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">为了得到损失的梯度<strong>l</strong>关于权重<strong>X</strong>的梯度，雅可比矩阵<strong>J</strong>是向量乘以向量<strong>v</strong><strong></strong></span></p> <p style="text-align:center;"><img decoding="async" class="rich_pages" src="http://img.555519.xyz/uploads/20230108/09d7044c0878c4c9583d9905530b29e7.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法"></p> <p class="md-end-block md-p" style="line-height:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;">这种计算雅可比矩阵并将其与向量<strong>v</strong>相乘的方法使PyTorch能够轻松地为非标量输出提供外部梯度。</span></p> <p> <img decoding="async" src="http://img.555519.xyz/uploads/20230108/7ea178cfe90f586a0961b9249544c533.jpg" alt="PyTorch的自动求导机制详细解析，PyTorch的核心魔法">—<br />  END—</p> <p style="min-height:1em;letter-spacing:.544px;width:inherit;font-family:'Open Sans', 'Clear Sans', 'Helvetica Neue', Helvetica, Arial, sans-serif;font-size:16px;"><span style="font-size:14px;letter-spacing:.544px;">英文原文：https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95</span></p> </div></div> 			                </div>
                <div class="clearfix"></div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/news/article-100964.htm">宠物粮品牌名称有哪些好听的（宠物粮生产厂家排名）</a></p>
                                        <p>下一个：<a href="/news/article-101695.htm">动物疫苗间隔多久打一次（动物疫苗打几次）</a></p>
                                    </div>
                                    </div>
                    <div class="col-md-3">
                        <div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/free-nodes/2025-4-20-clash-v2ray-ss-ssr.htm" title="「4月20日」最高速度18.9M/S，2025年Clash/Shadowrocket/V2ray/SSR每天更新免费机场订阅节点链接">「4月20日」最高速度18.9M/S，2025年Clash/Shadowrocket/V2ray/SSR每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-4-5-node-share-links.htm" title="「4月5日」最高速度22.2M/S，2025年V2ray/Shadowrocket/SSR/Clash每天更新免费机场订阅节点链接">「4月5日」最高速度22.2M/S，2025年V2ray/Shadowrocket/SSR/Clash每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/news/article-98756.htm" title="附近的宠物医院在哪里（附近的宠物医院宠物店）">附近的宠物医院在哪里（附近的宠物医院宠物店）</a></li>
                        <li class="py-2"><a href="/news/article-75807.htm" title="netty系列之:netty中的自动解码器ReplayingDecoder_在线工具">netty系列之:netty中的自动解码器ReplayingDecoder_在线工具</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-3-13-free-ssr-subscribe.htm" title="「3月13日」最高速度18.8M/S，2025年Shadowrocket/V2ray/Clash/SSR每天更新免费机场订阅节点链接">「3月13日」最高速度18.8M/S，2025年Shadowrocket/V2ray/Clash/SSR每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-3-7-clash-node.htm" title="「3月7日」最高速度19.1M/S，2025年V2ray/Shadowrocket/Clash/SSR每天更新免费机场订阅节点链接">「3月7日」最高速度19.1M/S，2025年V2ray/Shadowrocket/Clash/SSR每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/news/article-79221.htm" title="Python 3.10 的一些新特性">Python 3.10 的一些新特性</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-3-24-free-shadowrocket-node.htm" title="「3月24日」最高速度19.5M/S，2025年Clash/V2ray/Shadowrocket/SSR每天更新免费机场订阅节点链接">「3月24日」最高速度19.5M/S，2025年Clash/V2ray/Shadowrocket/SSR每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/free-nodes/2025-3-3-node-share-links.htm" title="「3月3日」最高速度21M/S，2025年Shadowrocket/SSR/V2ray/Clash每天更新免费机场订阅节点链接">「3月3日」最高速度21M/S，2025年Shadowrocket/SSR/V2ray/Clash每天更新免费机场订阅节点链接</a></li>
                        <li class="py-2"><a href="/news/article-93608.htm" title="长沙宠物领养吧（长沙宠物领养贴吧）">长沙宠物领养吧（长沙宠物领养贴吧）</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">66</span> <a href="/date/2025-04/" title="2025-04 归档">2025-04</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">89</span> <a href="/date/2025-03/" title="2025-03 归档">2025-03</a></h4>
            </li>
                    </ul>
    </div>
</div>

                    </div>
                </div>
            </div>
        </section>
    </main>
        <!-- Footer 3 - Bootstrap Brain Component -->
    <footer class="footer">
        <div class="border-top py-4 py-md-5 py-xl-8">
            <div class="container overflow-hidden">
                <div class="row gy-4 gy-md-0">
                    <div class="col-xs-12 col-md-12 order-2 order-md-1">
                        <div class="footer-copyright-wrapper text-center">
                                                <p>
                                                <a href="/">首页</a> |
                                                <a href="/free-nodes/">免费节点</a> |
                                                <a href="/paid-subscribe/">推荐机场</a> |
                                                <a href="/client.htm">客户端</a> |
                                                <a href="/news/">新闻资讯</a> |
                                                <a href="/about-us.htm">关于我们</a> |
                        <a href="/disclaimer.htm">免责申明</a> |
                        <a href="/privacy.htm">隐私申明</a> |
                        <a href="/sitemap.xml">网站地图</a>
                    </p>
                            WindowsClashNode节点订阅站 版权所有 Powered by WordPress
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    <script src="/assets/website/js/frontend/windowsclashnode/jquery-3.5.1.min.js"></script>
    <script src="/assets/website/js/frontend/windowsclashnode/bootstrap/bootstrap.bundle.min.js"></script>
    <!-- Javascript Files: Controllers -->
    <script src="/assets/website/js/frontend/windowsclashnode/global.js"></script>
    <script src="https://www.freeclashnode.com/assets/js/frontend/invite-url.js"></script>
    <script src="/assets/website/js/frontend/G.js"></script>
</body>

</html>